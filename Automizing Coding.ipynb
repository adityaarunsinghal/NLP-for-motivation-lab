{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import gensim.models\n",
    "import numpy as np\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import predictor\n",
    "from predictor import predictor\n",
    "from model_loader import model_loader\n",
    "\n",
    "data = pd.read_csv(\"/Users/aditya/Documents/GitHub/NLP-for-motivation-lab/data-reduced-joined.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'fit_time': array([0.73810506, 0.82576919, 0.5432539 ]), 'score_time': array([0.00217199, 0.00306273, 0.00094891]), 'test_score': array([0.84971098, 0.80924855, 0.84883721]), 'train_score': array([1.        , 0.9942029 , 0.99710983])}\n0.9565217391304348\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9565217391304348"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "# checking predictor performance for specificity\n",
    "\n",
    "mypredictor_s = predictor(data, 'all', k_neighbors = 3, min_df=1)\n",
    "mypredictor_s.train_on('s')\n",
    "mypredictor_s.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mypredictor_s.save_model(\"general_specificity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'fit_time': array([0.55008626, 0.33755708, 0.69498086]), 'score_time': array([0.00104284, 0.00157309, 0.00079608]), 'test_score': array([0.75      , 0.81632653, 0.78911565]), 'train_score': array([0.99319728, 0.99661017, 0.99322034])}\n"
     ]
    }
   ],
   "source": [
    "mypredictor_d = predictor(data, 'all', k_neighbors = 4, min_df=1)\n",
    "mypredictor_d.train_on('d')\n",
    "mypredictor_d.save_model(\"general_directness\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "coder1_specific_d = data[['all','d1','d2','d3']][:128]\n",
    "coder1_specific_d['d'] = round(coder1_specific_d[coder1_specific_d.columns[-3:]].mean(axis=1))\n",
    "coder2_specific_d = data[['all','d1','d2','d3']][128:]\n",
    "coder2_specific_d['d'] = round(coder2_specific_d[coder2_specific_d.columns[-3:]].mean(axis=1))\n",
    "coder3_specific_d = data[['all','d4','d5','d6']][:128]\n",
    "coder3_specific_d['d'] = round(coder3_specific_d[coder3_specific_d.columns[-3:]].mean(axis=1))\n",
    "coder4_specific_d = data[['all','d4','d5','d6']][128:]\n",
    "coder4_specific_d['d'] = round(coder4_specific_d[coder4_specific_d.columns[-3:]].mean(axis=1))\n",
    "\n",
    "coder1_specific_s = data[['all','s1','s2','s3']][:128]\n",
    "coder1_specific_s['s'] = round(coder1_specific_s[coder1_specific_s.columns[-3:]].mean(axis=1))\n",
    "coder2_specific_s = data[['all','s1','s2','s3']][128:]\n",
    "coder2_specific_s['s'] = round(coder2_specific_s[coder2_specific_s.columns[-3:]].mean(axis=1))\n",
    "coder3_specific_s = data[['all','s4','s5','s6']][:128]\n",
    "coder3_specific_s['s'] = round(coder3_specific_s[coder3_specific_s.columns[-3:]].mean(axis=1))\n",
    "coder4_specific_s = data[['all','s4','s5','s6']][128:]\n",
    "coder4_specific_s['s'] = round(coder4_specific_s[coder4_specific_s.columns[-3:]].mean(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSyntaxError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-c9e90af19196>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"mypredictor_coder{i}d = predictor(coder{i}_specific_d, 'all', k_neighbors = {k}, min_df=1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSyntaxError\u001b[0m: unexpected EOF while parsing (<string>, line 1)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-c9e90af19196>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mwhile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"mypredictor_coder{i}d = predictor(coder{i}_specific_d, 'all', k_neighbors = {k}, min_df=1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(1,5):\n",
    "    k = 4\n",
    "    while(True):\n",
    "        try:\n",
    "            exec(f\"mypredictor_coder{i}d = predictor(coder{i}_specific_d, 'all', k_neighbors = {k}, min_df=1\")\n",
    "            break\n",
    "        except: \n",
    "            k = k-1\n",
    "    exec(f\"mypredictor_coder{i}d.train_on('d')\")\n",
    "    exec(f\"print(mypredictor_coder{i}d.test())\")\n",
    "    exec(f\"mypredictor_coder{i}d.save_model('coder{i}_d')\")\n",
    "\n",
    "    k = 4\n",
    "    while(True):\n",
    "        try:\n",
    "            exec(f\"mypredictor_coder{i}s = predictor(coder{i}_specific_s, 'all', k_neighbors = {k}, min_df=1\")\n",
    "            break\n",
    "        except: \n",
    "            k = k-1\n",
    "    exec(f\"mypredictor_coder{i}s.train_on('s')\")\n",
    "    exec(f\"print(mypredictor_coder{i}s.test())\")\n",
    "    exec(f\"mypredictor_coder{i}s.save_model('coder{i}_s')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_coder(df, k, min, on, save_as):\n",
    "    mypredictor = predictor(df, 'all', k_neighbors = k, min_df=min)\n",
    "    mypredictor.train_on(on)\n",
    "    mypredictor.test()\n",
    "    mypredictor.save_model(save_as)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'fit_time': array([0.03772593, 0.04012084, 0.02670097]), 'score_time': array([0.00056314, 0.00056124, 0.00162101]), 'test_score': array([0.87692308, 0.859375  , 0.875     ]), 'train_score': array([0.96875   , 0.99224806, 0.97674419])}\n0.8857142857142857\n"
     ]
    }
   ],
   "source": [
    "test_coder(df = coder2_specific_s, k = 3, min = 2, on = 's', save_as = 'coder2_specific_s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make package and make it usable\n",
    "#better feature selection\n",
    "#normalize added features\n",
    "#better model explainibility\n",
    "#more hard-coded context (insider knowledge of the process)\n",
    "#better non-ad-hoc selection of hyperparamteres\n",
    "#give irmak averages of coder within reliabilities\n",
    "#neater pipelines\n",
    "#ask profs for ideas\n",
    "#push on github and maintain\n",
    "#make ready for coders to rely on \n",
    "#publish"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}